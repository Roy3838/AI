{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sys imports\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "# Training API\n",
    "import keras as keras\n",
    "from keras import layers\n",
    "import keras_nlp\n",
    "\n",
    "# Data manipulation and exploration\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, kurtosis\n",
    "\n",
    "# Data visualization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# MLOps API\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "There are 72M titles and views in the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADER \n",
    "def parse_jsonl_optimized(filepath, num_lines_to_import=None):\n",
    "    titles = []\n",
    "    view_counts = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for i, line in enumerate(tqdm(file, desc=\"Processing\")):\n",
    "            # Check if the specified number of lines has been reached (if specified)\n",
    "            if (num_lines_to_import is not None and i >= num_lines_to_import):\n",
    "                break\n",
    "            # Parse the current line\n",
    "            data = json.loads(line)\n",
    "            # Extract and store the title and view count\n",
    "            titles.append(data['title'])\n",
    "            view_counts.append(data['view_count'])\n",
    "    return titles, view_counts\n",
    "\n",
    "# Example usage: Import only the first 1000 lines from the file\n",
    "file_path = '/mnt/datassd/train_data.jsonl'\n",
    "num_lines_to_import = 50000  # You can adjust this number as needed\n",
    "titles, view_counts = parse_jsonl_optimized(file_path, num_lines_to_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create $Log_{10}(Data)$ and create tokenizer\n",
    "\n",
    "When views are analyzed on their own, the MSE loss function does not make a lot of sense, there is a lot of variation in the data.\n",
    "\n",
    "What's why we take $log_{10}$ to get the order of magnitude of the views ($10^x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_view_count = np.where(np.log10(view_counts) == -np.inf, 0, np.log10(view_counts))\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load BERT tokanizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding all 70M datapoints takes ~45mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SINGLE THREADED  \"\"\"\n",
    "encoded_inputs = [tokenizer.encode(title, add_special_tokens=True) for title in tqdm(titles, total=len(titles), desc=\"Encoding\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\" SOMEWHAT MULTITHREADED \"\"\"\n",
    "#def encode_title(title):\n",
    "#    return tokenizer.encode(title, add_special_tokens=True)\n",
    "#with ThreadPoolExecutor() as executor:\n",
    "#    encoded_inputs = list(tqdm(executor.map(encode_title, titles), total=len(titles), desc=\"Encoding\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of title engagement, UPPER CASED titles correlate with engagement, it is important to use a CASED tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cased inputs in tokenization\n",
    "titulos_raros = [r'IS THIS TOKEN Cased?']\n",
    "print(tokenizer.tokenize(titulos_raros[0]))\n",
    "tokenizer.encode(titulos_raros[0], add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization tests\n",
    "\n",
    "First, let's see the distribution of view counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Y view count distribution\n",
    "sns.histplot(y_view_count, kde=True)\n",
    "plt.title(\"Log of View Count Distribution\")\n",
    "plt.xlabel(\"Log of View Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_test_stat, shapiro_p_value = shapiro(y_view_count)\n",
    "kurtosis_value = kurtosis(y_view_count, fisher=True)\n",
    "\n",
    "shapiro_test_stat, shapiro_p_value, kurtosis_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the ditribution of lenghts of titles.\n",
    "\n",
    "We need to have a cutoff at a certain token lenght. So let's visualize when it would be appropriate to cut titles off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([len(encoded_input) for encoded_input in encoded_inputs], bins=50)\n",
    "plt.title(\"Histogram of tokenized title lengths\")\n",
    "plt.xlabel(\"Length of tokenized title\")\n",
    "plt.ylabel(\"Number of titles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably at 40 tokens, the cutoff would preserve most of the information. (Remember YouTube titles have a 100 char limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 40  # Ensure your data is adjusted accordingly\n",
    "\n",
    "padded_inputs = pad_sequences(encoded_inputs, maxlen=max_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just making sure, all inputs are the same length of 40 \n",
    "sns.histplot([len(padded_input) for padded_input in padded_inputs], bins=50)\n",
    "plt.title(\"Histogram of padded title lengths\")\n",
    "plt.xlabel(\"Length of padded title\")\n",
    "plt.ylabel(\"Number of titles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some samples to see the PADs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [tokenizer.decode(padded_input) for padded_input in padded_inputs[90:100]]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "vocab_size = 30522  # Adjusted to match BERT's vocabulary size for bert-base-cased\n",
    "embedding_dim = 256\n",
    "num_heads = 4\n",
    "intermediate_dim = 512\n",
    "transformer_encoder_layers = 3\n",
    "\n",
    "X_t = jnp.array(padded_inputs)\n",
    "Y_t = jnp.array(y_view_count)\n",
    "\n",
    "inputs = keras.Input(shape=(max_length,), dtype='int32')\n",
    "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=vocab_size, \n",
    "    sequence_length=max_length, \n",
    "    embedding_dim=embedding_dim,\n",
    ")\n",
    "\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "for _ in range(transformer_encoder_layers):\n",
    "    encoder = keras_nlp.layers.TransformerEncoder(\n",
    "        num_heads=num_heads,\n",
    "        intermediate_dim=intermediate_dim,\n",
    "        activation='relu',\n",
    "        dropout=0.1,\n",
    "    )\n",
    "    x = encoder(x)\n",
    "\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlflowCallbackLogPerBatch(mlflow.keras_core.MLflowCallback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.log_every_n_steps is None or logs is None:\n",
    "            return\n",
    "        if (batch + 1) % self.log_every_n_steps == 0:\n",
    "            self.metrics_logger.record_metrics(logs, self._log_step)\n",
    "            self._log_step += self.log_every_n_steps\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model.fit(X_t, Y_t, batch_size=32, epochs=10, validation_split=0.2, callbacks= [MlflowCallbackLogPerBatch(run, log_every_epoch=False, log_every_n_steps=5)])\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the eval dataset\n",
    "eval_file_path = '/mnt/datassd/eval_data.jsonl'\n",
    "titles_eval, view_counts_eval = parse_jsonl_optimized(file_path, 1000)\n",
    "encoded_evals = [tokenizer.encode(title, add_special_tokens=True) for title in tqdm(titles_eval, total=len(titles_eval), desc=\"Encoding\")]\n",
    "padded_evals = pad_sequences(encoded_evals, maxlen=max_length, padding='post', truncating='post')\n",
    "view_evals = np.where(np.log10(view_counts_eval) == -np.inf, 0, np.log10(view_counts_eval))\n",
    "X_e = jnp.array(padded_evals)\n",
    "Y_e = jnp.array(view_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_e)\n",
    "\n",
    "# Make scatter of predicted vs actual\n",
    "plt.scatter(Y_e, Y_pred)\n",
    "# Make a line\n",
    "plt.plot([0, 10], [0, 10], color='red')\n",
    "plt.title(\"Predicted vs Actual Log of View Count\")\n",
    "plt.xlabel(\"Actual Log of View Count\")\n",
    "plt.ylabel(\"Predicted Log of View Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
