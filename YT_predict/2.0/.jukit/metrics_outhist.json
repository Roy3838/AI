{"Y1ps5BQSbz": [], "oWVm17uamQ": [], "UZ5jTpSq96": [{"output_type": "stream", "name": "stdout", "text": "Model: \"functional_1\"\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)              \u2503 Output Shape       \u2503    Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer (InputLayer)  \u2502 (None, 100)        \u2502          0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 token_and_position_embed\u2026 \u2502 (None, 100, 256)   \u2502  2,585,600 \u2502\n\u2502 (TokenAndPositionEmbeddi\u2026 \u2502                    \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 transformer_encoder       \u2502 (None, 100, 256)   \u2502    527,104 \u2502\n\u2502 (TransformerEncoder)      \u2502                    \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_max_pooling1d      \u2502 (None, 256)        \u2502          0 \u2502\n\u2502 (GlobalMaxPooling1D)      \u2502                    \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense (Dense)             \u2502 (None, 256)        \u2502     65,792 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_1 (Dense)           \u2502 (None, 1)          \u2502        257 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n Total params: 3,178,753 (12.13 MB)\n Trainable params: 3,178,753 (12.13 MB)\n Non-trainable params: 0 (0.00 B)\n"}], "A5CwqIiqkS": [{"output_type": "stream", "name": "stdout", "text": "Epoch 1/10\n\u001b[0;31m-------------------------------------------------------------------\u001b[0m\n\u001b[0;31mXlaRuntimeError\u001b[0m                   Traceback (most recent call last)\nCell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m  \u001b[38;5;66;03m# This is now only for your reference and generator configuration\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Assuming your data_generator now correctly configures batches of size `batch_size`\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m83419\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Make sure this matches your actual number of batches per epoch)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Log additional metrics or parameters\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, vocab_size)\n\nFile \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:613\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# If original function succeeds, but `patch_function_exception` exists,\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;66;03m# it represent patching code unexpected failure, so we call\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# even if `patch_function_exception` exists, because original function failure\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m# means there's some error in user code (e.g. user provide wrong arguments)\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m patch_function_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m failed_during_original:\n\nFile \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:494\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    487\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    488\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m         og_kwargs,\n\u001b[1;32m    493\u001b[0m     )\n\u001b[0;32m--> 494\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    497\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    498\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m         og_kwargs,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n\nFile \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n\n    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n\nFile \u001b[0;32m~/.local/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1209\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1211\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n\n\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2250625704 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   36.77MiB\n              constant allocation:         0B\n        maybe_live_out allocation:   36.38MiB\n     preallocated temp allocation:    2.10GiB\n  preallocated temp fragmentation:   96.00MiB (4.47%)\n                 total allocation:    2.13GiB\n              total fragmentation:   96.01MiB (4.40%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 312.50MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/div\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/nn.py\" source_line=89\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,8,100,100]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 312.50MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/jvp(aecd,abcd->acbe)/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/numpy.py\" source_line=55\n\t\tXLA Label: custom-call\n\t\tShape: f32[8192,100,100]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 200.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/jvp(jit(relu))/max\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/nn.py\" source_line=19\n\t\tXLA Label: fusion\n\t\tShape: f32[102400,512]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 200.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/numpy.py\" source_line=93\n\t\tXLA Label: custom-call\n\t\tShape: f32[102400,512]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add_any\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/nn.py\" source_line=513\n\t\tXLA Label: fusion\n\t\tShape: f32[256,1024,100]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/layers/core/einsum_dense.py\" source_line=228\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,8,100,32]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add_any\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/nn.py\" source_line=513\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,100,256]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 100.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[100,256,1024]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/layers/normalization/layer_normalization.py\" source_line=229\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,100,256]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 100.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[100,256,1024]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/jvp(acbe,aecd->abcd)/transpose[permutation=(0, 3, 1, 2)]\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/numpy.py\" source_line=55 deduplicated_name=\"input_transpose_fusion.2\"\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,100,8,32]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/mul\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/jax/numpy.py\" source_line=134\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,8,100,32]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/layers/core/einsum_dense.py\" source_line=228\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,8,32,100]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 100.00MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/add\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras_nlp/src/layers/modeling/token_and_position_embedding.py\" source_line=135\n\t\tXLA Label: fusion\n\t\tShape: f32[1024,100,256]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 9.77MiB\n\t\tOperator: op_name=\"jit(compiled_train_step)/jit(main)/sub\" source_file=\"/home/jay/.local/lib/python3.11/site-packages/keras/src/backend/common/variables.py\" source_line=283\n\t\tXLA Label: fusion\n\t\tShape: f32[10000,256]\n\t\t==========================\n\n\n"}], "NjVou6EDo0": [{"output_type": "stream", "name": "stdout", "text": "\u001b[0;31m-------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                    Traceback (most recent call last)\nCell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model.save(f'{actual_model_name}.keras')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYT_transformer.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#predictions = model.predict(X_test)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#for i in range(10):  # Display first 10 predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#    print(f\"Predicted view count: {predictions[i]}, Actual view count: {y_test[i]}\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\n\u001b[0;31mAttributeError\u001b[0m: module 'keras' has no attribute 'load_model'\n"}]}