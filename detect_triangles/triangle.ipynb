{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to recheck the triangle computer vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# First we create some framework as a testing base\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class TriangleDataset(Dataset):\n",
    "    def __init__(self, dataset_path, labels, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img_path = os.path.join(self.dataset_path, label['file_name'])\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        vertices = np.array(label['vertices']).flatten()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(predicted_vertices, real_vertices):\n",
    "    \"\"\"\n",
    "    Calculate the distance from each predicted vertex to the nearest real vertex.\n",
    "\n",
    "    Parameters:\n",
    "    predicted_vertices (np.ndarray): 2D array of predicted vertices [N, 2].\n",
    "    real_vertices (np.ndarray): 2D array of real vertices [M, 2].\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - distances (np.ndarray): The distances of predicted vertices to their nearest real vertex.\n",
    "        - closest_indices (np.ndarray): The indices of the closest real vertices to each predicted vertex.\n",
    "    \"\"\"\n",
    "    # Calculate all pairwise distances\n",
    "    distances = cdist(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Find the index of the closest real vertex for each predicted vertex\n",
    "    closest_indices = np.argmin(distances, axis=1)\n",
    "    \n",
    "    # Find the minimum distance for each predicted vertex\n",
    "    min_distances = distances[np.arange(len(predicted_vertices)), closest_indices]\n",
    "    \n",
    "    return min_distances, closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertices(image, real_vertices, predicted_vertices):\n",
    "    \"\"\"\n",
    "    Plot the image, real vertices, predicted vertices, and lines between predicted vertices and their closest real vertices.\n",
    "    Annotate the lines with the calculated distances.\n",
    "\n",
    "    Parameters:\n",
    "    image (torch.Tensor): The image tensor.\n",
    "    real_vertices (np.ndarray): Real vertices as a numpy array.\n",
    "    predicted_vertices (np.ndarray): Predicted vertices as a numpy array.\n",
    "    \"\"\"\n",
    "    # Ensure real and predicted vertices are in the correct shape\n",
    "    real_vertices = real_vertices.reshape((-1, 2))\n",
    "    predicted_vertices = predicted_vertices.reshape((-1, 2))\n",
    "\n",
    "    # Convert the image tensor to a numpy array for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image_np = image.squeeze().numpy()\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        image_np = image\n",
    "    else:\n",
    "        raise TypeError(\"Image must be a torch.Tensor or np.ndarray.\")\n",
    "    \n",
    "    # Calculate distances and closest indices\n",
    "    min_distances, closest_indices = calculate_distances(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_np, cmap='gray')\n",
    "    plt.scatter(real_vertices[:, 0], real_vertices[:, 1], color='green', label='Real Vertices')\n",
    "    plt.scatter(predicted_vertices[:, 0], predicted_vertices[:, 1], color='red', label='Predicted Vertices')\n",
    "    \n",
    "    # Draw lines and annotate distances\n",
    "    for i, (dist, closest_idx) in enumerate(zip(min_distances, closest_indices)):\n",
    "        pred_vertex = predicted_vertices[i]\n",
    "        closest_real_vertex = real_vertices[closest_idx]\n",
    "        plt.plot([pred_vertex[0], closest_real_vertex[0]], [pred_vertex[1], closest_real_vertex[1]], 'b--')\n",
    "        mid_point = (pred_vertex + closest_real_vertex) / 2\n",
    "        plt.text(mid_point[0], mid_point[1], f'{dist:.2f}', color='blue')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " array([18, 27,  7, 10, 22, 11]),\n",
       " array([15, 25, 35, 55, 65, 25]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "dataset_path = '/home/jay/repos/AI/data/triangles_dataset/'\n",
    "labels = np.load(os.path.join(dataset_path, 'labels.npy'), allow_pickle=True)\n",
    "\n",
    "# Remember to resize images to 640x480 if not already\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),  # Resize to match input size\n",
    "    transforms.ToTensor(),\n",
    "    # Add any additional transformations if needed\n",
    "])\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = TriangleDataset(dataset_path, labels, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "image, real_vertices = dataset[0]  # This gets the first item; adjust the index as needed\n",
    "\n",
    "\n",
    "predicted_vertices = np.array([15, 25, 35, 55, 65, 25])  # Example predicted vertices\n",
    "\n",
    "image, real_vertices, predicted_vertices\n",
    "\n",
    "\n",
    "\n",
    "plot_vertices(image, real_vertices, predicted_vertices)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
