{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# You can use 'tensorflow', 'torch' or 'jax' as backend. Make sure to set the environment variable before importing.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "mlflow.autolog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 10:27:25.308278: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 10:27:25.380819: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 10:27:25.380844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 10:27:25.381885: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 10:27:25.390113: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 10:27:25.390485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 10:27:26.344870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024/02/27 10:27:27 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "/home/jay/.local/lib/python3.11/site-packages/keras_core/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33856</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,166,848</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                 │        <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │        \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33856\u001b[0m)             │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │  \u001b[38;5;34m2,166,848\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                 │        \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,195,302</span> (8.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,195,302\u001b[0m (8.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,195,302</span> (8.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,195,302\u001b[0m (8.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras_core\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    INPUT_SHAPE = (100, 100, 1)  # Assuming grayscale images of 100x100 pixels\n",
    "    model = keras_core.Sequential(\n",
    "        [\n",
    "            keras_core.layers.Input(shape=INPUT_SHAPE),\n",
    "            keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.MaxPooling2D((2, 2)),\n",
    "            # Add more Conv2D or MaxPooling2D layers as needed\n",
    "            # keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            # keras_core.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.Flatten(),\n",
    "            keras_core.layers.Dense(64, activation='relu'),\n",
    "            keras_core.layers.Dense(6)  # Predicting 6 values for the vertices\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model= keras_core.Sequential()\n",
    "model.add(keras_core.layers.Input(shape=(100,100,1)))\n",
    "model.add(keras_core.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "model.add(keras_core.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "model.add(keras_core.layers.MaxPool2D(2,2))\n",
    "model.add(keras_core.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras_core.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras_core.layers.MaxPool2D(2,2))\n",
    "\n",
    "model.add(keras_core.layers.Flatten())\n",
    "model.add(keras_core.layers.Dense(64, activation='relu'))\n",
    "model.add(keras_core.layers.Dropout(0.25))\n",
    "model.add(keras_core.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "# model = initialize_model()\n",
    "model.summary()\n",
    "# keras_core.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path, size=(100, 100)):\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert('L')  # Convert to grayscale\n",
    "        img = img.resize(size)  # Resize image\n",
    "        return np.array(img)\n",
    "\n",
    "def load_dataset(dataset_path, labels, size=(100, 100)):\n",
    "    num_samples = len(labels)\n",
    "    # Assuming images are grayscale, adjust the shape accordingly\n",
    "    # For RGB images, use size + (3,)\n",
    "    images = np.zeros((num_samples, size[0], size[1]), dtype=np.float32)\n",
    "    vertices = np.zeros((num_samples, 6), dtype=np.float32)  # Adjust size based on label structure\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        img_path = os.path.join(dataset_path, label['file_name'])\n",
    "        images[idx] = load_image(img_path, size=size) / 255.0  # Normalize images\n",
    "        vertices[idx] = np.array(label['vertices']).flatten()\n",
    "\n",
    "    return images, vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/jay/repos/AI/data/triangles_dataset/'\n",
    "labels = np.load(os.path.join(dataset_path, 'labels.npy'), allow_pickle=True)\n",
    "\n",
    "images, vertices = load_dataset(dataset_path, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Assuming the vertices are stored as (x1, y1, x2, y2, x3, y3)\n",
    "    true_vertices = K.reshape(y_true, (-1, 3, 2))\n",
    "    pred_vertices = K.reshape(y_pred, (-1, 3, 2))\n",
    "\n",
    "    # Calculate the true and predicted centers\n",
    "    true_center = K.mean(true_vertices, axis=1)\n",
    "    pred_center = K.mean(pred_vertices, axis=1)\n",
    "\n",
    "    # Calculate the distance between the true vertices and the predicted center\n",
    "    center_distances = K.sqrt(K.sum(K.square(true_vertices - pred_center[:, None, :]), axis=-1))\n",
    "\n",
    "    # The loss is the mean squared error of the vertices plus a penalty term for the center distances\n",
    "    C=4\n",
    "    vertex_loss = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "    center_penalty = K.mean(center_distances, axis=-1)*C\n",
    "\n",
    "    return vertex_loss + center_penalty\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=custom_loss,  # Example for a regression task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=images,\n",
    "    y=vertices,\n",
    "    batch_size=40,\n",
    "    epochs=8,\n",
    "    validation_split=0.1  # You can use validation split directly with NumPy arrays\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plot_vertices(image, real_vertices, predicted_vertices, calculate_distances):\n",
    "    \"\"\"\n",
    "    Plot the image, real vertices, predicted vertices, and lines between predicted vertices and their closest real vertices.\n",
    "    Annotate the lines with the calculated distances and display the sum of distances.\n",
    "\n",
    "    Parameters:\n",
    "    image (torch.Tensor or np.ndarray): The image tensor or numpy array.\n",
    "    real_vertices (np.ndarray): Real vertices as a numpy array.\n",
    "    predicted_vertices (np.ndarray): Predicted vertices as a numpy array.\n",
    "    calculate_distances (function): Function to calculate distances and closest indices.\n",
    "    \"\"\"\n",
    "    # Ensure real and predicted vertices are in the correct shape\n",
    "    real_vertices = real_vertices.reshape((-1, 2))\n",
    "    predicted_vertices = predicted_vertices.reshape((-1, 2))\n",
    "\n",
    "    # Convert the image tensor to a numpy array for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image_np = image.detach().cpu().numpy().squeeze()  # Adjusted for potential tensor characteristics\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        image_np = image\n",
    "    else:\n",
    "        raise TypeError(\"Image must be a torch.Tensor or np.ndarray.\")\n",
    "    \n",
    "    # Calculate distances and closest indices using the provided function\n",
    "    min_distances, closest_indices = calculate_distances(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Calculate the sum of the distances\n",
    "    sum_of_distances = np.sum(min_distances)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np, cmap='gray')\n",
    "    plt.scatter(real_vertices[:, 0], real_vertices[:, 1], color='green', label='Real Vertices')\n",
    "    plt.scatter(predicted_vertices[:, 0], predicted_vertices[:, 1], color='red', label='Predicted Vertices')\n",
    "    \n",
    "    # Draw lines and annotate distances\n",
    "    for i, (dist, closest_idx) in enumerate(zip(min_distances, closest_indices)):\n",
    "        pred_vertex = predicted_vertices[i]\n",
    "        closest_real_vertex = real_vertices[closest_idx]\n",
    "        plt.plot([pred_vertex[0], closest_real_vertex[0]], [pred_vertex[1], closest_real_vertex[1]], 'b--')\n",
    "        mid_point = (pred_vertex + closest_real_vertex) / 2\n",
    "        plt.text(mid_point[0], mid_point[1], f'{dist:.2f}', color='blue')\n",
    "    \n",
    "    # Display the sum of distances\n",
    "    plt.title(f'Sum of Distances: {sum_of_distances:.2f}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_distances(predicted_vertices, real_vertices):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the distance from each predicted vertex to the nearest real vertex,\n",
    "    ensuring that no two predicted vertices are paired with the same real vertex.\n",
    "\n",
    "    Parameters:\n",
    "    predicted_vertices (np.ndarray): 2D array of predicted vertices [N, 2].\n",
    "    real_vertices (np.ndarray): 2D array of real vertices [M, 2].\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - distances (np.ndarray): The distances of predicted vertices to their assigned real vertex.\n",
    "        - assignment_indices (np.ndarray): The indices of the real vertices assigned to each predicted vertex.\n",
    "    \"\"\"\n",
    "    # Calculate all pairwise distances\n",
    "    distances = cdist(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Solve the assignment problem\n",
    "    predicted_indices, real_indices = linear_sum_assignment(distances)\n",
    "    \n",
    "    # Calculate the minimum distances based on the optimal assignment\n",
    "    min_distances = distances[predicted_indices, real_indices]\n",
    "    \n",
    "    return min_distances, real_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(images))\n",
    "plot_vertices(images[random_index], vertices[random_index], model.predict(images[random_index][None, ...]), calculate_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
