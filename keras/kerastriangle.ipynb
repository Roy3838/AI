{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# You can use 'tensorflow', 'torch' or 'jax' as backend. Make sure to set the environment variable before importing.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "mlflow.autolog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ensure TensorFlow 2.x is used\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "# Set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_core\n",
    "\n",
    "def initialize_model():\n",
    "    INPUT_SHAPE = (100, 100, 1)  # Assuming grayscale images of 100x100 pixels\n",
    "    model = keras_core.Sequential(\n",
    "        [\n",
    "            keras_core.layers.Input(shape=INPUT_SHAPE),\n",
    "            keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.MaxPooling2D((2, 2)),\n",
    "            # Add more Conv2D or MaxPooling2D layers as needed\n",
    "            # keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            # keras_core.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.Flatten(),\n",
    "            keras_core.layers.Dense(64, activation='relu'),\n",
    "            keras_core.layers.Dense(6)  # Predicting 6 values for the vertices\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# model= keras_core.Sequential()\n",
    "# model.add(keras_core.layers.Input(shape=(100,100,1)))\n",
    "# model.add(keras_core.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
    "# model.add(keras_core.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "# model.add(keras_core.layers.MaxPool2D(2,2))\n",
    "# model.add(keras_core.layers.Dropout(0.25))\n",
    "\n",
    "# model.add(keras_core.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "# model.add(keras_core.layers.MaxPool2D(2,2))\n",
    "\n",
    "# model.add(keras_core.layers.Flatten())\n",
    "# model.add(keras_core.layers.Dense(64, activation='relu'))\n",
    "# model.add(keras_core.layers.Dropout(0.25))\n",
    "# model.add(keras_core.layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model = initialize_model()\n",
    "model.summary()\n",
    "# keras_core.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path, size=(100, 100)):\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert('L')  # Convert to grayscale\n",
    "        img = img.resize(size)  # Resize image\n",
    "        return np.array(img)\n",
    "\n",
    "def load_dataset(dataset_path, labels, size=(100, 100)):\n",
    "    num_samples = len(labels)\n",
    "    # Assuming images are grayscale, adjust the shape accordingly\n",
    "    # For RGB images, use size + (3,)\n",
    "    images = np.zeros((num_samples, size[0], size[1]), dtype=np.float32)\n",
    "    vertices = np.zeros((num_samples, 6), dtype=np.float32)  # Adjust size based on label structure\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        img_path = os.path.join(dataset_path, label['file_name'])\n",
    "        images[idx] = load_image(img_path, size=size) / 255.0  # Normalize images\n",
    "        vertices[idx] = np.array(label['vertices']).flatten()\n",
    "\n",
    "    return images, vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/jay/AI/data/triangles_dataset/'\n",
    "labels = np.load(os.path.join(dataset_path, 'labels.npy'), allow_pickle=True)\n",
    "\n",
    "images, vertices = load_dataset(dataset_path, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import keras\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Assuming the vertices are stored as (x1, y1, x2, y2, x3, y3)\n",
    "    true_vertices = K.reshape(y_true, (-1, 3, 2))\n",
    "    pred_vertices = K.reshape(y_pred, (-1, 3, 2))\n",
    "\n",
    "    # Calculate the true and predicted centers\n",
    "    true_center = K.mean(true_vertices, axis=1)\n",
    "    pred_center = K.mean(pred_vertices, axis=1)\n",
    "\n",
    "    # Calculate the distance between the true vertices and the predicted center\n",
    "    center_distances = K.sqrt(K.sum(K.square(true_vertices - pred_center[:, None, :]), axis=-1))\n",
    "\n",
    "    # The loss is the mean squared error of the vertices plus a penalty term for the center distances\n",
    "    C=4\n",
    "    vertex_loss = K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "    center_penalty = K.mean(center_distances, axis=-1)*C\n",
    "\n",
    "    return vertex_loss + center_penalty\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=custom_loss, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(\n",
    "    x=images,\n",
    "    y=vertices,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_split=0.1  # You can use validation split directly with NumPy arrays\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plot_vertices(image, real_vertices, predicted_vertices, calculate_distances):\n",
    "    \"\"\"\n",
    "    Plot the image, real vertices, predicted vertices, and lines between predicted vertices and their closest real vertices.\n",
    "    Annotate the lines with the calculated distances and display the sum of distances.\n",
    "\n",
    "    Parameters:\n",
    "    image (torch.Tensor or np.ndarray): The image tensor or numpy array.\n",
    "    real_vertices (np.ndarray): Real vertices as a numpy array.\n",
    "    predicted_vertices (np.ndarray): Predicted vertices as a numpy array.\n",
    "    calculate_distances (function): Function to calculate distances and closest indices.\n",
    "    \"\"\"\n",
    "    # Ensure real and predicted vertices are in the correct shape\n",
    "    real_vertices = real_vertices.reshape((-1, 2))\n",
    "    predicted_vertices = predicted_vertices.reshape((-1, 2))\n",
    "\n",
    "    # Convert the image tensor to a numpy array for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image_np = image.detach().cpu().numpy().squeeze()  # Adjusted for potential tensor characteristics\n",
    "    elif isinstance(image, np.ndarray):\n",
    "        image_np = image\n",
    "    else:\n",
    "        raise TypeError(\"Image must be a torch.Tensor or np.ndarray.\")\n",
    "    \n",
    "    # Calculate distances and closest indices using the provided function\n",
    "    min_distances, closest_indices = calculate_distances(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Calculate the sum of the distances\n",
    "    sum_of_distances = np.sum(min_distances)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np, cmap='gray')\n",
    "    plt.scatter(real_vertices[:, 0], real_vertices[:, 1], color='green', label='Real Vertices')\n",
    "    plt.scatter(predicted_vertices[:, 0], predicted_vertices[:, 1], color='red', label='Predicted Vertices')\n",
    "    \n",
    "    # Draw lines and annotate distances\n",
    "    for i, (dist, closest_idx) in enumerate(zip(min_distances, closest_indices)):\n",
    "        pred_vertex = predicted_vertices[i]\n",
    "        closest_real_vertex = real_vertices[closest_idx]\n",
    "        plt.plot([pred_vertex[0], closest_real_vertex[0]], [pred_vertex[1], closest_real_vertex[1]], 'b--')\n",
    "        mid_point = (pred_vertex + closest_real_vertex) / 2\n",
    "        plt.text(mid_point[0], mid_point[1], f'{dist:.2f}', color='blue')\n",
    "    \n",
    "    # Display the sum of distances\n",
    "    plt.title(f'Sum of Distances: {sum_of_distances:.2f}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_distances(predicted_vertices, real_vertices):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the distance from each predicted vertex to the nearest real vertex,\n",
    "    ensuring that no two predicted vertices are paired with the same real vertex.\n",
    "\n",
    "    Parameters:\n",
    "    predicted_vertices (np.ndarray): 2D array of predicted vertices [N, 2].\n",
    "    real_vertices (np.ndarray): 2D array of real vertices [M, 2].\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - distances (np.ndarray): The distances of predicted vertices to their assigned real vertex.\n",
    "        - assignment_indices (np.ndarray): The indices of the real vertices assigned to each predicted vertex.\n",
    "    \"\"\"\n",
    "    # Calculate all pairwise distances\n",
    "    distances = cdist(predicted_vertices, real_vertices)\n",
    "    \n",
    "    # Solve the assignment problem\n",
    "    predicted_indices, real_indices = linear_sum_assignment(distances)\n",
    "    \n",
    "    # Calculate the minimum distances based on the optimal assignment\n",
    "    min_distances = distances[predicted_indices, real_indices]\n",
    "    \n",
    "    return min_distances, real_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(images))\n",
    "plot_vertices(images[random_index], vertices[random_index], model.predict(images[random_index][None, ...]), calculate_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_path = '/home/jay/AI/data/triangles_test/'\n",
    "labels_test = np.load(os.path.join(dataset_test_path, 'labels.npy'), allow_pickle=True)\n",
    "\n",
    "images_test, vertices_test = load_dataset(dataset_test_path, labels_test)\n",
    "\n",
    "random_index = np.random.randint(0, len(images_test))\n",
    "print(random_index)\n",
    "plot_vertices(images_test[random_index], vertices_test[random_index], model.predict(images_test[random_index][None, ...]), calculate_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
